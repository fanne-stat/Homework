b <- matrix(c(pi, beta), nrow=2, ncol=1)
nbr <- mnr(b, x.dat, x.cat)
cat("\n", "  Maximum likelihood estimators")
cat("\n", "     pi = ", nbr$b[1])
cat("\n", "   beta = ", nbr$b[2], "\n")
cat("\n", "  Covariance matrix =", nbr$hi )
#  Compute expected counts for the
#  negative binomial model
m.nb <- sum(x.dat)*prob(nbr$b, x.dat, x.cat)
#  Combine categories in the right
#  tail of the distribution
nc <- length(x.dat)
xcc <- combine(x.cat, x.dat, m.nb, nc, mb)
# Compute the Pearson chi-squared
# test and p-value
x2p <- sum(((xcc$xt-xcc$ept)^2)/xcc$ept)
dfp <- length(xcc$ept) - 3
pvalp <- 1 - pchisq(x2p, dfp)
# Compute the G^2 statistic
g2<-0
for(i in 1:length(xcc$ept)) {
at<-0
if(xcc$xt[i] > 0)
{at<-2*xcc$xt[i]*log(xcc$xt[i]/xcc$ept[i])}
g2 <- g2+at}
pvalg <- 1-pchisq(g2, dfp)
#  print results
kk <- length(xcc$ept)
new3 <- matrix(c(xcc$cl, xcc$cu, xcc$xt, xcc$ept), kk, 4)
cat("\n", "  Results for fitting the Negative Binomial distribution", "\n")
cat("\n", "Category Bounds   Count   Expected", "\n")
print(new3)
cat("\n", "         Pearson test = ", x2p)
cat("\n", "   Degrees of freedom = ", dfp)
cat("\n", "              p-value = ", pvalp)
cat("\n", "Likelihood ratio test = ", g2)
cat("\n", "                   df = ", dfp)
cat("\n", "              p-value = " , pvalg)
source('C:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw2YifanZhu/negbin(2).R')
source('C:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw2YifanZhu/negbin(2).R', echo=TRUE)
source('C:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw2YifanZhu/negbin(2).R')
?cumprod
source('C:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw2YifanZhu/rainevents.R')
comb
source('C:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw2YifanZhu/rainevents.R')
source('C:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw2YifanZhu/negbin(2).R')
pi
pi <- nbr$b[1]
beta <- nbr$b[2]
invI <- nbr$hi
invI
mhat
mhat <- beta*(1-pi)/pi
mhat
D <- c(-beta/pi^2, (1-pi)/pi)
t(D)%*%invI%*%D
sqrt(0.03306799)
sigama <- sqrt(0.03306799)
mhat - 1.96*sigma
mhat - 1.96*sigama
mhat +1.96*sigama
log(2.93)+1.96*sqrt(1/67 + 1/34 + 1/43 + 1/64)
log(2.93) - 1.96*sqrt(1/67 + 1/34 + 1/43 + 1/64)
exp(0.509591)
exp(1.640414)
fisher.test(matrix(c(21,2,15,3),ncol=2, byrow=T))
library(vcd)
install.packages("vcd")
library(vcd)
x <- matrix(c(48, 26, 22, 8, 2, 4,
6, 4), nrow = 2, byrow=T)
assocstats(x)
assocstats(t(x))
xm<- matrix(c(113, 163, 370, 45, 106, 280,229, 343, 568), nrow = 3, byrow=T)
assocstats(xf)
xf<- matrix(c(100, 109, 202, 33, 89, 179,100, 179, 542), nrow = 3, byrow=T)
assocstats(xf)
assocstats(xm)
?fisher.test
fisher.test
x
fisher.test(x, simulate.p.value = T, B = 50000)
assocstats(xf)
assocstats(xm)
x
fisher.test(x)
Gamma2.f<-function(x, pr=0.95)
{
# x is a matrix of counts. You can use output of xtabs in R.
# Confidence interval calculation and output from Greg Rodd
# Check for using S-PLUS and output is from crosstabs (needs >= S-PLUS 6.0)
if(is.null(version$language) && inherits(x, "crosstabs")) { oldClass(x)<-NULL;
attr(x, "marginals")<-NULL}
n <- nrow(x)
m <- ncol(x)
pi.c<-pi.d<-matrix(0,nr=n,nc=m)
row.x<-row(x)
col.x<-col(x)
for(i in 1:(n)){
for(j in 1:(m)){
pi.c[i, j]<-sum(x[row.x<i & col.x<j]) + sum(x[row.x>i & col.x>j])
pi.d[i, j]<-sum(x[row.x<i & col.x>j]) + sum(x[row.x>i & col.x<j])}}
C <- sum(pi.c*x)/2
D <- sum(pi.d*x)/2
psi<-2*(D*pi.c-C*pi.d)/(C+D)^2
sigma2<-sum(x*psi^2)-sum(x*psi)^2
gamma <- (C - D)/(C + D)
pr2 <- 1 - (1 - pr)/2
CIa <- qnorm(pr2) * sqrt(sigma2) * c(-1, 1) + gamma
list(gamma = gamma, C = C, D = D, sigma = sqrt(sigma2), Level = paste(
100 * pr, "%", sep = ""), CI = paste(c("[", max(CIa[1], -1),
", ", min(CIa[2], 1), "]"), collapse = ""))
}
Gamma2.f(xf)
Gamma2.f(xm)
xb <- matrix(c(10, 5, 10, 31, 10, 4,
22, 18, 9), 3, 3, byrow=T)
xw <- matrix(c(9, 10, 5, 26, 6, 13,
10, 17, 10), 3, 3, byrow=T)
#   This file contains R code for computing a
#   Kappa statistic, or weighted Kappa statistic,
#   standard errors and confidence intervals.
#   It is applied to the student teacher data.
#   The file is posted as  kappa.R
# First create a function to compute kappa
kappa.f <- function(x, w=NULL)
{
#  Compute expected counts for random agreement
n <- sum(x)
xr <- apply(x, 1, sum)
xc <- apply(x, 2, sum)
one <- rep(1, length(xr))
e <- outer(xr, xc)/n
#  Compute the unweighted Kappa
k1 <- sum(diag(x))/n
k2 <- sum(diag(e))/n
k3 <- sum(diag(x)*diag(xr+xc))/(n*n)
k4 <- sum(((outer(xc, one)+
outer(one, xr))**2)*x)/(n**3)
kappa <- (k1-k2)/(1-k2)
#  Compute standard errors:
#     s1 does not assume random agreement
#     s2 assumes only random agreement
s11 <- (k1*(1-k1)/((1-k2)**2)+2*(1-k1)*
(2*k1*k2-k3)/((1-k2)**3)+
((1-k1)**2)*(k4-4*k2*k2)/((1-k2)**4))/n
s1 <- s11**.5
s22 <- (k2+k2*k2-(sum(diag(e)*diag(xr+xc))
/(n**2)))/(n*(1-k2)**2)
s2 <- s22**.5
# Compute default weights if no weights are provided
k <- dim(x)[2]
if (is.null(w)) {
w <- matrix(0, ncol = k, nrow = k)
for (i in 1:k) {
for (j in 1:k) {
w[i, j] <- 1 - (abs(i - j))^2/(k-1)^2
}
}
}
#  Compute the weighted Kappa
xw <- x*w
ew <- e*w
wr <- apply(w*xc, 2, sum)/n
wc <- apply(w*xr, 2, sum)/n
kw1 <- sum(xw)/n
kw2 <- sum(ew)/n
tt2 <- outer(wr, one)+outer(one, wc)
tt3 <- ((w*(1-kw2))-(tt2*(1-kw1)))**2
kappaw <- (kw1-kw2)/(1-kw2)
#  Compute standard errors:
#     sw11 does not assume random agreement
#     sw22  assumes only random agreement
sw11 <- sum(x*tt3)/n
sw11 <- (sw11-(kw1*kw2-2*kw2+kw1)**2)/
(n*(1-kw2)**4)
sw1 <- sw11**.5
sw22 <- (w-tt2)**2
sw22 <- ((sum(e*sw22)/n)-(kw2**2))/
(n*(1-kw2)**2)
sw2 <- sw22**.5
#  Construct 95% confidence intervals
#  and tests for random agreement
tk <- kappa/s2
tkw <- kappaw/sw2
tt4 <- tk**2
pk <- (1-pchisq(tt4, 1))
tt4 <- tkw**2
pkw <-(1-pchisq(tt4, 1))
ckl <- kappa-(1.96)*s1
cku <- kappa+(1.96)*s1
ckwl <- kappaw-(1.96)*sw1
ckwu <- kappaw+(1.96)*sw1
ww <- matrix( w, ncol=k, nrow=k)
#print results
cat("\n", "       Unweighted Kappa = ", signif(kappa,5))
cat("\n", "         Standard error = ", signif(s1,5))
cat("\n", "95% confidence interval:  ", signif(ckl,5), signif(cku,5))
cat("\n", "p-value for test of random agreement = ", signif(pk,5), "\n", "\n")
cat("\n", "         Weighted Kappa = ", signif(kappaw,5))
cat("\n", "         Standard error = ", signif(sw1,5))
cat("\n", "95% confidence interval:  ", signif(ckwl,5), signif(ckwu,5))
cat("\n", "p-value for test of random agreement = ", signif(pkw,5),"\n")
}
kappa.f(xw)
kappa.f(xb)
source('C:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw2YifanZhu/kappaboot.R')
results
boot.ci(results, type="all", index=1)
?boot.ci
source('C:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw2YifanZhu/kappaboot.R')
boot.ci(results, type="all", index=1)
0.061583^2 +  0.054328^2
-0.12456 - (-0.073792)
-0.050768 - 1.96 *0.006743997
-0.050768 + 1.96 *0.006743997
x.array <- array(c(81, 34, 24, 71, 118, 74, 69, 105, 82, 63, 52, 93),c(2,2,3))
mantelhaen.test(x.array, conf.level=0.95)
?mantelhaen.test
library(DescTools)
install.packages("DescTools")
library(DescTools)
BreslowDayTest(x.array)
mantelhaen.test(x.array, conf.level=0.95, exact = T)
?Zelen
??zelen
install.packages("NSM3")
library(NSM3)
zelen.test(x.array)
?zelen.test
zelen.test(example = T)
zelen.test(x.array, 5)
zelen.test(x.array, r = 5)
install.packages("VGAM")
ï¼Ÿcontr.poly
?contr.poly
contr.poly(3)
library(VGAM)
mlogit <- vglm(cbind(single, divorced, married) ~ z, family=multinomial, data=ddat)
ddat <- read.table("dmstatus.dat",
col.names=c("x","single","married","divorced","total"))
ddat
ddat$ps <- ddat$single/ddat$total
ddat$pm <- ddat$married/ddat$total
ddat$pd <- ddat$divorced/ddat$total
ddat$z <- ddat$x-16
ddat$lz <- log(ddat$z)
ddat
ddat <- read.table("dmstatus.dat",
col.names=c("x","single","married","divorced","total"))
setwd("c:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw4YifanZhu/")
ddat <- read.table("dmstatus.dat",
col.names=c("x","single","married","divorced","total"))
ddat
#  Compute sample proportions and subtract
#  16 from the age values
ddat$ps <- ddat$single/ddat$total
ddat$pm <- ddat$married/ddat$total
ddat$pd <- ddat$divorced/ddat$total
ddat$z <- ddat$x-16
ddat$lz <- log(ddat$z)
ddat
# Fit a polychotomous logistic regression
# model using married as the baseline
options(contrasts = c("contr.treatment", "contr.poly"))
mlogit <- vglm(cbind(single, divorced, married) ~ z, family=multinomial, data=ddat)
summary(mlogit)
#  plot the estimated curves
a <- seq(0,59,1)
ax <- a+16
ay <- a/59
pp <- predict(mlogit, data.frame(z=a),type="response")
par(fin=c(5.5,5.5),pch=18,mkh=.1,mex=1.5)
plot(ax, ay, type="n",
xlab="Age",
ylab="Probability",
main="Danish Marital Status")
lines(ax, pp[ , 1], lty=1, lwd=3)
lines(ax, pp[ , 2], lty=3, lwd=3)
lines(ax, pp[ , 3], lty=2, lwd=3)
points(ddat$x, ddat$ps, pch=15, mkh=.2)
points(ddat$x, ddat$pd, pch=17, mkh=.2)
points(ddat$x, ddat$pm, pch=6, mkh=.2)
legend(50, 1.04,c("Single", "Divorced",
"Married"),lty=c(1,3,2),bty="n")
dsing <- ddat[ , c(1,2,5,6,9,10)]
colnames(dsing) <- c("x", "count", "total", "p", "z", "logz")
dsing$y <- 1
ddiv <-  ddat[ , c(1,3,5,7,9,10)]
colnames(ddiv) <- c("x", "count", "total", "p", "z", "logz")
ddiv$y <- 2
dmar <- ddat[ , c(1,4,5,8,9,10)]
colnames(dmar) <- c("x", "count", "total", "p", "z", "logz")
dmar$y <- 3
ddats <- rbind(dsing, ddiv, dmar)
ddats$y <- as.factor(ddats$y)
library(MASS)
clogit <- polr(y ~ z, weights=count, data=ddats, Hess=TRUE)
summary(clogit)
coef(clogit)
predict(clogit, ddats, type="probs")
a <- seq(0,59,1)
ax <- a+16
ay <- a/59
pp <- predict(clogit, data.frame(z=a),type="probs")
par(fin=c(5.5,5.5),pch=18,mkh=.1,mex=1.5)
plot(ax, ay, type="n",
xlab="Age",
ylab="Probability",
main="Danish Marital Status")
lines(ax, pp[ , 1], lty=1, lwd=3)
lines(ax, pp[ , 2], lty=3, lwd=3)
lines(ax, pp[ , 3], lty=2, lwd=3)
points(ddat$x, ddat$ps, pch=15, mkh=.2)
points(ddat$x, ddat$pd, pch=17, mkh=.2)
points(ddat$x, ddat$pm, pch=6, mkh=.2)
legend(50, 1.04,c("Single", "Divorced",
"Married"),lty=c(1,3,2),bty="n")
?polr
?contr.poly
?polr
summary(mlogit)
predict(mlogit, ddat, type="response")
1 - pchisq(24.3237, 12)
1 - pchisq(q = 24.3237, df = 12)
a <- seq(0,59,1)
ax <- a+16
ay <- a/59
pp <- predict(mlogit, data.frame(z=a),type="response")
par(fin=c(5.5,5.5),pch=18,mkh=.1,mex=1.5)
plot(ax, ay, type="n",
xlab="Age",
ylab="Probability",
main="Danish Marital Status")
lines(ax, pp[ , 1], lty=1, lwd=3)
lines(ax, pp[ , 2], lty=3, lwd=3)
lines(ax, pp[ , 3], lty=2, lwd=3)
points(ddat$x, ddat$ps, pch=15, mkh=.2)
points(ddat$x, ddat$pd, pch=17, mkh=.2)
points(ddat$x, ddat$pm, pch=6, mkh=.2)
legend(50, 1.04,c("Single", "Divorced",
"Married"),lty=c(1,3,2),bty="n")
ddat$z2 <- (ddat$z)^2
ddat$lz2 <- (ddat$lz)^2
mlogit2 <- vglm(cbind(single, divorced, married) ~ z + z2, family=multinomial, data=ddat)
summary(mlogit2)
a <- seq(0,59,1)
ax <- a+16
ay <- a/59
pp <- predict(mlogit2, data.frame(z=a),type="response")
par(fin=c(5.5,5.5),pch=18,mkh=.1,mex=1.5)
plot(ax, ay, type="n",
xlab="Age",
ylab="Probability",
main="Danish Marital Status")
lines(ax, pp[ , 1], lty=1, lwd=3)
lines(ax, pp[ , 2], lty=3, lwd=3)
lines(ax, pp[ , 3], lty=2, lwd=3)
points(ddat$x, ddat$ps, pch=15, mkh=.2)
points(ddat$x, ddat$pd, pch=17, mkh=.2)
points(ddat$x, ddat$pm, pch=6, mkh=.2)
legend(50, 1.04,c("Single", "Divorced",
"Married"),lty=c(1,3,2),bty="n")
a <- seq(0,59,1)
ax <- a+16
ay <- a/59
pp <- predict(mlogit, data.frame(z=a, z2=a^2),type="response")
par(fin=c(5.5,5.5),pch=18,mkh=.1,mex=1.5)
plot(ax, ay, type="n",
xlab="Age",
ylab="Probability",
main="Danish Marital Status")
lines(ax, pp[ , 1], lty=1, lwd=3)
lines(ax, pp[ , 2], lty=3, lwd=3)
lines(ax, pp[ , 3], lty=2, lwd=3)
points(ddat$x, ddat$ps, pch=15, mkh=.2)
points(ddat$x, ddat$pd, pch=17, mkh=.2)
points(ddat$x, ddat$pm, pch=6, mkh=.2)
legend(50, 1.04,c("Single", "Divorced",
"Married"),lty=c(1,3,2),bty="n")
a <- seq(0,59,1)
ax <- a+16
ay <- a/59
pp <- predict(mlogit2, data.frame(z=a, z2 = a),type="response")
par(fin=c(5.5,5.5),pch=18,mkh=.1,mex=1.5)
plot(ax, ay, type="n",
xlab="Age",
ylab="Probability",
main="Danish Marital Status")
lines(ax, pp[ , 1], lty=1, lwd=3)
lines(ax, pp[ , 2], lty=3, lwd=3)
lines(ax, pp[ , 3], lty=2, lwd=3)
points(ddat$x, ddat$ps, pch=15, mkh=.2)
points(ddat$x, ddat$pd, pch=17, mkh=.2)
points(ddat$x, ddat$pm, pch=6, mkh=.2)
legend(50, 1.04,c("Single", "Divorced",
"Married"),lty=c(1,3,2),bty="n")
summary(mlogit2)
1 - pchisq(8.6595, df = 10)
#--------------------------------------------------------
mlogit3 <- vglm(cbind(single, divorced, married) ~ lz, family=multinomial, data=ddat)
summary(mlogit2)
summary(mlogit3)
a <- seq(0,59,1)
ax <- log(a+16)
ay <- a/59
pp <- predict(mlogit3, data.frame(lz = log(a)),type="response")
par(fin=c(5.5,5.5),pch=18,mkh=.1,mex=1.5)
plot(ax, ay, type="n",
xlab="Age",
ylab="Probability",
main="Danish Marital Status")
lines(ax, pp[ , 1], lty=1, lwd=3)
lines(ax, pp[ , 2], lty=3, lwd=3)
lines(ax, pp[ , 3], lty=2, lwd=3)
points(ddat$x, ddat$ps, pch=15, mkh=.2)
points(ddat$x, ddat$pd, pch=17, mkh=.2)
points(ddat$x, ddat$pm, pch=6, mkh=.2)
legend(50, 1.04,c("Single", "Divorced",
"Married"),lty=c(1,3,2),bty="n")
a <- seq(0.1,59,1)
ax <- log(a+16)
ay <- a/59
pp <- predict(mlogit3, data.frame(lz = log(a)),type="response")
par(fin=c(5.5,5.5),pch=18,mkh=.1,mex=1.5)
plot(ax, ay, type="n",
xlab="Age",
ylab="Probability",
main="Danish Marital Status")
lines(ax, pp[ , 1], lty=1, lwd=3)
lines(ax, pp[ , 2], lty=3, lwd=3)
lines(ax, pp[ , 3], lty=2, lwd=3)
points(ddat$x, ddat$ps, pch=15, mkh=.2)
points(ddat$x, ddat$pd, pch=17, mkh=.2)
points(ddat$x, ddat$pm, pch=6, mkh=.2)
legend(50, 1.04,c("Single", "Divorced",
"Married"),lty=c(1,3,2),bty="n")
a <- seq(1,59,1)
ax <- log(a+16)
ay <- a/59
pp <- predict(mlogit3, data.frame(lz = log(a)),type="response")
pp <- predict(mlogit3, data.frame(lz = log(a)),type="response")
par(fin=c(5.5,5.5),pch=18,mkh=.1,mex=1.5)
plot(ax, ay, type="n",
xlab="Age",
ylab="Probability",
main="Danish Marital Status")
lines(ax, pp[ , 1], lty=1, lwd=3)
lines(ax, pp[ , 2], lty=3, lwd=3)
lines(ax, pp[ , 3], lty=2, lwd=3)
points(ddat$x, ddat$ps, pch=15, mkh=.2)
points(ddat$x, ddat$pd, pch=17, mkh=.2)
points(ddat$x, ddat$pm, pch=6, mkh=.2)
legend(50, 1.04,c("Single", "Divorced",
"Married"),lty=c(1,3,2),bty="n")
points(ddat$x, ddat$ps, pch=15, mkh=.2)
a <- seq(1,59,1)
ax <- a+16
ay <- a/59
pp <- predict(mlogit3, data.frame(lz = log(a)),type="response")
par(fin=c(5.5,5.5),pch=18,mkh=.1,mex=1.5)
plot(ax, ay, type="n",
xlab="Age",
ylab="Probability",
main="Danish Marital Status")
lines(ax, pp[ , 1], lty=1, lwd=3)
lines(ax, pp[ , 2], lty=3, lwd=3)
lines(ax, pp[ , 3], lty=2, lwd=3)
points(ddat$x, ddat$ps, pch=15, mkh=.2)
points(ddat$x, ddat$pd, pch=17, mkh=.2)
points(ddat$x, ddat$pm, pch=6, mkh=.2)
legend(50, 1.04,c("Single", "Divorced",
"Married"),lty=c(1,3,2),bty="n")
summary(mlogit3)
1 - pchisq(7.8249, df = 12)
mlogit4 <- vglm(cbind(single, divorced, married) ~ lz + lz2, family=multinomial, data=ddat)
summary(mlogit4)
a <- seq(1,59,1)
ax <- a+16
ay <- a/59
pp <- predict(mlogit4, data.frame(lz = log(a), lz2 = (log(a))^2),type="response")
par(fin=c(5.5,5.5),pch=18,mkh=.1,mex=1.5)
plot(ax, ay, type="n",
xlab="Age",
ylab="Probability",
main="Danish Marital Status")
lines(ax, pp[ , 1], lty=1, lwd=3)
lines(ax, pp[ , 2], lty=3, lwd=3)
lines(ax, pp[ , 3], lty=2, lwd=3)
points(ddat$x, ddat$ps, pch=15, mkh=.2)
points(ddat$x, ddat$pd, pch=17, mkh=.2)
points(ddat$x, ddat$pm, pch=6, mkh=.2)
legend(50, 1.04,c("Single", "Divorced",
"Married"),lty=c(1,3,2),bty="n")
1 - pchisq(1.7077, df = 10)
deviance(mlogit)
nparam(mlogit)
AIC(mlogit)
BIC(mlogit)
return(c(nparam(x), deviance(x), AIC(x), BIC(x)))
etable <- function(x){
return(c(nparam(x), deviance(x), AIC(x),BIC(x)))
}
etable(mlogit)
etable(c(mlogit,mlogit2)
)
etable(mlogit2)
etable(mlogit3)
etable(mlogit4)
ddat <- read.table("dmstatus.dat",
col.names=c("x","single","married","divorced","total"))
ddat
