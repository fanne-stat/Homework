#  All categories preceeding K must
#  be included, even if the observed
#  count is zero. There should be K+1
#  entries in the list of counts.
x.dat <- c(57,203,383,525,532,408,273,139,45,27,10,4,0,1,1)
mb<-2
#  Enter the category values
nc <- length(x.dat)
x.cat <- 0:(nc-1)
#  Compute the total count, mean,
#  and variance
n <- sum(x.dat)
m.x <- crossprod(x.dat, x.cat)/n
v.x <- (crossprod(x.dat, x.cat^2) - n*m.x^2)/n
#  Compute expected counts for
#  the Poisson model
m.p <- (n/m.x)*exp(-m.x)*
cumprod(m.x*(c(1,1:(length(x.dat)-1))^(-1)))
# Combine categories to keep expected
# counts above a lower bound
xcc <- combine(x.cat, x.dat, m.p, nc, mb)
# Compute the Pearson chi-squared
# test and p-value
x2p <- sum((xcc$xt-xcc$ept)^2/xcc$ept)
dfp <- length(xcc$ept) - 2
pvalp <- 1 - pchisq(x2p, dfp)
# Compute the G^2 statistic
g2<-0
for(i in 1:length(xcc$ept)) {
at<-0
if(xcc$xt[i] > 0)
{at<-2*xcc$xt[i]*log(xcc$xt[i]/xcc$ept[i])}
g2 <- g2+at}
pvalg <- 1 - pchisq(g2, dfp)
# Compute the Fisher Index of Dispersion test statistic
# The one-sided alternative is that the variance is
# larger than the mean.
fisherd <- n*v.x/m.x
dff <- n -1
pvalf <- 1 - pchisq(fisherd, dff)
# Print results
kk <- length(xcc$ept)
new2 <- matrix(c(xcc$cl, xcc$cu, xcc$xt, xcc$ept),
kk, 4)
cat("\n", "  Results for fitting the
Poisson distribution", "\n")
cat("\n", "Category Bounds  Count  Expected", "\n")
print(new2)
cat("\n", "      Pearson test = ", x2p)
cat("\n", "Degrees of freedom = ", dfp)
cat("\n", "           p-value = ", pvalp, "\n")
cat("   Likelihood ratio test =", g2, "\n")
cat("                      df =", dfp, "\n")
cat("                  p-value =", pvalg, "\n")
cat("\n","Fisher Index of Dispersion = ", fisherd)
cat("\n", "    Degrees of freedom = ", dff)
cat("\n", "               p-value = ", pvalf )
#  Begin computation for fitting the
#  negative binomial distribution
pi <- .95
beta <- 20
if(v.x > m.x) {pi <- m.x/v.x
beta <- m.x^2/(v.x-m.x) }
cat("\n", "Results for fitting the
negative binomial distribution", "\n")
cat("\n", "  Method of moment estimators ")
cat("\n", "     pi = ", pi)
cat("\n", "   beta = ", beta, "\n")
#  Compute maximum likelihood estimates
b <- matrix(c(pi, beta), nrow=2, ncol=1)
nbr <- mnr(b, x.dat, x.cat)
cat("\n", "  Maximum likelihood estimators")
cat("\n", "     pi = ", nbr$b[1])
cat("\n", "   beta = ", nbr$b[2], "\n")
cat("\n", "  Covariance matrix =", nbr$hi )
#  Compute expected counts for the
#  negative binomial model
m.nb <- sum(x.dat)*prob(nbr$b, x.dat, x.cat)
#  Combine categories in the right
#  tail of the distribution
nc <- length(x.dat)
xcc <- combine(x.cat, x.dat, m.nb, nc, mb)
# Compute the Pearson chi-squared
# test and p-value
x2p <- sum(((xcc$xt-xcc$ept)^2)/xcc$ept)
dfp <- length(xcc$ept) - 3
pvalp <- 1 - pchisq(x2p, dfp)
# Compute the G^2 statistic
g2<-0
for(i in 1:length(xcc$ept)) {
at<-0
if(xcc$xt[i] > 0)
{at<-2*xcc$xt[i]*log(xcc$xt[i]/xcc$ept[i])}
g2 <- g2+at}
pvalg <- 1-pchisq(g2, dfp)
#  print results
kk <- length(xcc$ept)
new3 <- matrix(c(xcc$cl, xcc$cu, xcc$xt, xcc$ept), kk, 4)
cat("\n", "  Results for fitting the Negative Binomial distribution", "\n")
cat("\n", "Category Bounds   Count   Expected", "\n")
print(new3)
cat("\n", "         Pearson test = ", x2p)
cat("\n", "   Degrees of freedom = ", dfp)
cat("\n", "              p-value = ", pvalp)
cat("\n", "Likelihood ratio test = ", g2)
cat("\n", "                   df = ", dfp)
cat("\n", "              p-value = " , pvalg)
source('C:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw2YifanZhu/negbin(2).R')
source('C:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw2YifanZhu/negbin(2).R', echo=TRUE)
source('C:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw2YifanZhu/negbin(2).R')
?cumprod
source('C:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw2YifanZhu/rainevents.R')
comb
source('C:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw2YifanZhu/rainevents.R')
source('C:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw2YifanZhu/negbin(2).R')
pi
pi <- nbr$b[1]
beta <- nbr$b[2]
invI <- nbr$hi
invI
mhat
mhat <- beta*(1-pi)/pi
mhat
D <- c(-beta/pi^2, (1-pi)/pi)
t(D)%*%invI%*%D
sqrt(0.03306799)
sigama <- sqrt(0.03306799)
mhat - 1.96*sigma
mhat - 1.96*sigama
mhat +1.96*sigama
log(2.93)+1.96*sqrt(1/67 + 1/34 + 1/43 + 1/64)
log(2.93) - 1.96*sqrt(1/67 + 1/34 + 1/43 + 1/64)
exp(0.509591)
exp(1.640414)
fisher.test(matrix(c(21,2,15,3),ncol=2, byrow=T))
library(vcd)
install.packages("vcd")
library(vcd)
x <- matrix(c(48, 26, 22, 8, 2, 4,
6, 4), nrow = 2, byrow=T)
assocstats(x)
assocstats(t(x))
xm<- matrix(c(113, 163, 370, 45, 106, 280,229, 343, 568), nrow = 3, byrow=T)
assocstats(xf)
xf<- matrix(c(100, 109, 202, 33, 89, 179,100, 179, 542), nrow = 3, byrow=T)
assocstats(xf)
assocstats(xm)
?fisher.test
fisher.test
x
fisher.test(x, simulate.p.value = T, B = 50000)
assocstats(xf)
assocstats(xm)
x
fisher.test(x)
Gamma2.f<-function(x, pr=0.95)
{
# x is a matrix of counts. You can use output of xtabs in R.
# Confidence interval calculation and output from Greg Rodd
# Check for using S-PLUS and output is from crosstabs (needs >= S-PLUS 6.0)
if(is.null(version$language) && inherits(x, "crosstabs")) { oldClass(x)<-NULL;
attr(x, "marginals")<-NULL}
n <- nrow(x)
m <- ncol(x)
pi.c<-pi.d<-matrix(0,nr=n,nc=m)
row.x<-row(x)
col.x<-col(x)
for(i in 1:(n)){
for(j in 1:(m)){
pi.c[i, j]<-sum(x[row.x<i & col.x<j]) + sum(x[row.x>i & col.x>j])
pi.d[i, j]<-sum(x[row.x<i & col.x>j]) + sum(x[row.x>i & col.x<j])}}
C <- sum(pi.c*x)/2
D <- sum(pi.d*x)/2
psi<-2*(D*pi.c-C*pi.d)/(C+D)^2
sigma2<-sum(x*psi^2)-sum(x*psi)^2
gamma <- (C - D)/(C + D)
pr2 <- 1 - (1 - pr)/2
CIa <- qnorm(pr2) * sqrt(sigma2) * c(-1, 1) + gamma
list(gamma = gamma, C = C, D = D, sigma = sqrt(sigma2), Level = paste(
100 * pr, "%", sep = ""), CI = paste(c("[", max(CIa[1], -1),
", ", min(CIa[2], 1), "]"), collapse = ""))
}
Gamma2.f(xf)
Gamma2.f(xm)
xb <- matrix(c(10, 5, 10, 31, 10, 4,
22, 18, 9), 3, 3, byrow=T)
xw <- matrix(c(9, 10, 5, 26, 6, 13,
10, 17, 10), 3, 3, byrow=T)
#   This file contains R code for computing a
#   Kappa statistic, or weighted Kappa statistic,
#   standard errors and confidence intervals.
#   It is applied to the student teacher data.
#   The file is posted as  kappa.R
# First create a function to compute kappa
kappa.f <- function(x, w=NULL)
{
#  Compute expected counts for random agreement
n <- sum(x)
xr <- apply(x, 1, sum)
xc <- apply(x, 2, sum)
one <- rep(1, length(xr))
e <- outer(xr, xc)/n
#  Compute the unweighted Kappa
k1 <- sum(diag(x))/n
k2 <- sum(diag(e))/n
k3 <- sum(diag(x)*diag(xr+xc))/(n*n)
k4 <- sum(((outer(xc, one)+
outer(one, xr))**2)*x)/(n**3)
kappa <- (k1-k2)/(1-k2)
#  Compute standard errors:
#     s1 does not assume random agreement
#     s2 assumes only random agreement
s11 <- (k1*(1-k1)/((1-k2)**2)+2*(1-k1)*
(2*k1*k2-k3)/((1-k2)**3)+
((1-k1)**2)*(k4-4*k2*k2)/((1-k2)**4))/n
s1 <- s11**.5
s22 <- (k2+k2*k2-(sum(diag(e)*diag(xr+xc))
/(n**2)))/(n*(1-k2)**2)
s2 <- s22**.5
# Compute default weights if no weights are provided
k <- dim(x)[2]
if (is.null(w)) {
w <- matrix(0, ncol = k, nrow = k)
for (i in 1:k) {
for (j in 1:k) {
w[i, j] <- 1 - (abs(i - j))^2/(k-1)^2
}
}
}
#  Compute the weighted Kappa
xw <- x*w
ew <- e*w
wr <- apply(w*xc, 2, sum)/n
wc <- apply(w*xr, 2, sum)/n
kw1 <- sum(xw)/n
kw2 <- sum(ew)/n
tt2 <- outer(wr, one)+outer(one, wc)
tt3 <- ((w*(1-kw2))-(tt2*(1-kw1)))**2
kappaw <- (kw1-kw2)/(1-kw2)
#  Compute standard errors:
#     sw11 does not assume random agreement
#     sw22  assumes only random agreement
sw11 <- sum(x*tt3)/n
sw11 <- (sw11-(kw1*kw2-2*kw2+kw1)**2)/
(n*(1-kw2)**4)
sw1 <- sw11**.5
sw22 <- (w-tt2)**2
sw22 <- ((sum(e*sw22)/n)-(kw2**2))/
(n*(1-kw2)**2)
sw2 <- sw22**.5
#  Construct 95% confidence intervals
#  and tests for random agreement
tk <- kappa/s2
tkw <- kappaw/sw2
tt4 <- tk**2
pk <- (1-pchisq(tt4, 1))
tt4 <- tkw**2
pkw <-(1-pchisq(tt4, 1))
ckl <- kappa-(1.96)*s1
cku <- kappa+(1.96)*s1
ckwl <- kappaw-(1.96)*sw1
ckwu <- kappaw+(1.96)*sw1
ww <- matrix( w, ncol=k, nrow=k)
#print results
cat("\n", "       Unweighted Kappa = ", signif(kappa,5))
cat("\n", "         Standard error = ", signif(s1,5))
cat("\n", "95% confidence interval:  ", signif(ckl,5), signif(cku,5))
cat("\n", "p-value for test of random agreement = ", signif(pk,5), "\n", "\n")
cat("\n", "         Weighted Kappa = ", signif(kappaw,5))
cat("\n", "         Standard error = ", signif(sw1,5))
cat("\n", "95% confidence interval:  ", signif(ckwl,5), signif(ckwu,5))
cat("\n", "p-value for test of random agreement = ", signif(pkw,5),"\n")
}
kappa.f(xw)
kappa.f(xb)
source('C:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw2YifanZhu/kappaboot.R')
results
boot.ci(results, type="all", index=1)
?boot.ci
source('C:/Users/fanne/Dropbox/Homework/STAT557/STAT557hw2YifanZhu/kappaboot.R')
boot.ci(results, type="all", index=1)
0.061583^2 +  0.054328^2
-0.12456 - (-0.073792)
-0.050768 - 1.96 *0.006743997
-0.050768 + 1.96 *0.006743997
x.array <- array(c(81, 34, 24, 71, 118, 74, 69, 105, 82, 63, 52, 93),c(2,2,3))
mantelhaen.test(x.array, conf.level=0.95)
?mantelhaen.test
library(DescTools)
install.packages("DescTools")
library(DescTools)
BreslowDayTest(x.array)
mantelhaen.test(x.array, conf.level=0.95, exact = T)
?Zelen
??zelen
install.packages("NSM3")
library(NSM3)
zelen.test(x.array)
?zelen.test
zelen.test(example = T)
zelen.test(x.array, 5)
zelen.test(x.array, r = 5)
install.packages("VGAM")
M <- c(500, 1000*1:10, 20000, 50000, 100000, 200000)
M
?boot
library(boot)
?boot
aircondit
d <- data.frame(n = 10, lambda = 5, method1 = c(1,2,3))
d
?row.names
row.names(d) <- c("m1, m2, m3")
row.names(d) <- c("", m1, m2, m3")
)
row.names(d)
row.names(d) <- c("m1", "m2", "m3")
d
rm(d)
for (M in c(100)){
xs <- matrix(rnorm(M*N), ncol = N)
ys <- matrix(rnorm(M*N), ncol = N)
for (n in 1:N){
P1Ms[n] <- P1M(xs[,n],y[,n])
P2Ms[n] <- P2M(xs[,n],y[,n])
}
P1Mss <- rbind(P1Mss, P1Ms)
P2Mss <- rbind(P2Mss, P2Ms)
}
Ms <- c(100*1:10, 2000)
N <- 2000
P1Ms <- rep(0, N)
P2Ms <- P1Ms
P1M <- function(x,y){
M <- length(x)
return(sum(x<y)/M)
}
P2M <- function(x,y){
M <- length(x)
x1 <- rep(x, times = M)
y1 <- rep(y, each = M)
return(sum(x1 < y1)/M^2)
}
P1Mss <- NULL
P2Mss <- NULL
for (M in c(100)){
xs <- matrix(rnorm(M*N), ncol = N)
ys <- matrix(rnorm(M*N), ncol = N)
for (n in 1:N){
P1Ms[n] <- P1M(xs[,n],y[,n])
P2Ms[n] <- P2M(xs[,n],y[,n])
}
P1Mss <- rbind(P1Mss, P1Ms)
P2Mss <- rbind(P2Mss, P2Ms)
}
for (M in c(100)){
xs <- matrix(rnorm(M*N), ncol = N)
ys <- matrix(rnorm(M*N), ncol = N)
for (n in 1:N){
P1Ms[n] <- P1M(xs[,n],ys[,n])
P2Ms[n] <- P2M(xs[,n],ys[,n])
}
P1Mss <- rbind(P1Mss, P1Ms)
P2Mss <- rbind(P2Mss, P2Ms)
}
P1Mss
head(P1Mss)
P1Mss[1:5]
P1Mss[,1:5]
length(xs[,1])
for (M in c(1000)){
xs <- matrix(rnorm(M*N), ncol = N)
ys <- matrix(rnorm(M*N), ncol = N)
for (n in 1:N){
P1Ms[n] <- P1M(xs[,n],ys[,n])
P2Ms[n] <- P2M(xs[,n],ys[,n])
}
P1Mss <- rbind(P1Mss, P1Ms)
P2Mss <- rbind(P2Mss, P2Ms)
}
dim(P1Mss)
?var
apply(P1Mss, dim = 2, var)
apply(P1Mss, dim = 2, FUN = var)
apply(P1Mss, MARGIN = 2, FUN = var)
apply(P1Mss, MARGIN = 1, FUN = var)
apply(P2Mss, MARGIN = 1, FUN = var)
apply(P1Mss, MARGIN = 1, FUN = var)/apply(P1Mss, MARGIN = 1, FUN = var)
apply(P1Mss, MARGIN = 1, FUN = var)/apply(P2Mss, MARGIN = 1, FUN = var)
P1Mss <- NULL
P2Mss <- NULL
Ms <- c(100*1:10, 2000)
N <- 2000
P1Ms <- rep(0, N)
P2Ms <- P1Ms
for (M in Ms){
xs <- matrix(rnorm(M*N), ncol = N)
ys <- matrix(rnorm(M*N), ncol = N)
for (n in 1:N){
P1Ms[n] <- P1M(xs[,n],ys[,n])
P2Ms[n] <- P2M(xs[,n],ys[,n])
}
P1Mss <- cbind(P1Mss, P1Ms)
P2Mss <- cbind(P2Mss, P2Ms)
}
ep1m <- apply(P1Mss, MARGIN = 2, FUN = mean)
ep1m <- apply(P2Mss, MARGIN = 2, FUN = mean)
varp1m <- apply(P1Mss, MARGIN = 2, FUN = var)
varp2m <- apply(P2Mss, MARGIN = 2, FUN = var)
ep1m
ep2m
ep1m <- apply(P1Mss, MARGIN = 2, FUN = mean)
ep2m <- apply(P2Mss, MARGIN = 2, FUN = mean)
ep1m
ep2m
varp1m
varp2m
varp1m/varp2m
library(dplyr)
?filter
?mask
??mask
?maply
library(plyr)
detach(dplyr)
detach("dplyr")
unloadNamespace("dplyr")
unloadNamespace("plyr")
library(plyr)
detach("package:dplyr", TRUE)
detach("package:plyr", TRUE)
detach("package:dplyr", TRUE)
library(dplyr)
detach("package:dplyr", TRUE)
library(plyr)
library(plyr); library(dplyr)
?maply
maply(cbind(1:5, 1:5), rnorm, n = 5)
maply(cbind(1:3, 1:3), rnorm, n = 5)
maply(cbind(1:3, 1:3, 1:3), rnorm, n = 5)
maply(cbind(1:3, 1:3), rnorm, n = 5)
maply(cbind(1:3, 1:3), rnorm, n = 5, mean = 0)
maply(cbind(1:3, 1:3), rnorm, n = 5, mean = 0, sd = 1)
aaply(cbind(1:3, 1:3), .margins = c(1,2), rnorm, n = 5, mean = 0, sd = 1)
aaply(cbind(1:3, 1:3), .margins = c(1,2), rnorm, n = 5, mean = 0)
#1
##(a)
olive <- read.table(file = "http://maitra.public.iastate.edu/stat501/datasets/olive.dat")
head(olive)
#1
##(a)
olive <- read.table(file = "http://maitra.public.iastate.edu/stat501/datasets/olive.dat", header = T)
head(olive)
levels(group.id)
levels(olive$group.id)
levels(as.factor(olive$group.id))
?stars
?radar
??radar
??spider
?stars
stars(mtcars[, 1:7], locations = c(0, 0), radius = FALSE,
key.loc = c(0, 0), main = "Motor Trend Cars", lty = 2)
mtcars[,1:7]
attach(airquality)
Month <- factor(Month, labels = month.abb[5:9])
Mon
Month
month.abb
airquality
pairwise.t.test(Ozone, Month)
source('C:/Users/fanne/Dropbox/Homework/STAT501/project 1/radviz3d-2.R', echo=TRUE)
?density
senator
setwd("C:/Users/fanne/Dropbox/Homework/STAT501/STAT501hw1YifanZhu")
library(readxl)
senators<-read_xls("senate_voting_data.xls")
#b) Plot Andrews' curves
senators.names<-names(senators)[-c(1,2)]
rev.party.state.names<-lapply(X=strsplit(gsub(pattern="[.]",replacement="",x=senators.names),split=" "),FUN = rev)
senators.party <- lapply(X = rev.party.state.names, FUN = function(x)(unlist(x)[1]))
senators.party <- unlist(senators.party)
senators.last.names <- lapply(X = rev.party.state.names, FUN = function(x)(unlist(x)[4]))
senators.last.names <- unlist(senators.last.names)
senators
#Create new data.frame for plotting
senators_new <- as.data.frame(t(senators[,-c(1,2)]))
summary(senators_new)
senators_new
colnames(senators_new) <- NULL
rownames(senators_new) <- NULL
senators_new
senators_new <- data.frame(senators_new, party = senators.party)
senators_new
#Create new data.frame for plotting
senators_new <- as.data.frame(t(senators[,-c(1,2)]))
bw.ucv(x = as.vector(senators_new))
as.vector(senators_new)
c(senators_new)
?as.vector
aa <- as.numeric(senators_new)
aa <- as.matrix(senators_new)
aa
dim(aa) <- NULL
aa
bw.ucv(x = aa)
?bw.ucv
bw.ucv(x = aa, nb = length(aa))
bw.ucv(x = aa, nb = length(aa), lower = 1e-4)
bw.nrd(x = aa)
bw.ucv(x = aa, nb = length(aa), lower = 1e-6)
bw.SJ(x = aa, nb = length(aa), lower = 1e-6)
